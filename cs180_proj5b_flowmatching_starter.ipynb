{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LIYunzhe1408/Flow-Matching/blob/main/cs180_proj5b_flowmatching_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR0SKBDbaOqR"
      },
      "source": [
        "# Project 5B: Flow Matching from Scratch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMrLOORbWLz"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lX3XpcGSXBIs",
        "outputId": "c551b278-993d-4ea2-d790-907a764f1a95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# We recommend using these utils.\n",
        "# https://google.github.io/mediapy/mediapy.html\n",
        "# https://einops.rocks/\n",
        "!pip install mediapy einops --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VdFQ6c9-Pm4Y"
      },
      "outputs": [],
      "source": [
        "# Import essential modules. Feel free to add whatever you need.\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZZziMrxiIk"
      },
      "source": [
        "# Part 1: Training a Single-step Denoising UNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dokvxybn_DwK"
      },
      "source": [
        "## Implementing Simple and Composed Ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fhpEzgwCJqbW"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, in_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Unconditional UNet"
      ],
      "metadata": {
        "id": "tsntLNl8PkdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94h1Q3BxN0ha"
      },
      "outputs": [],
      "source": [
        "class UnconditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ObcO_jUamVE"
      },
      "source": [
        "# Part 2: Flow Matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMI3IMkjayxQ"
      },
      "source": [
        "## Implementing a Time-conditioned UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkchbyYkzAvV"
      },
      "outputs": [],
      "source": [
        "class FCBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class TimeConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nyxOM-RbZnC"
      },
      "source": [
        "## Implementing the Forward and Reverse Process for Time-conditioned Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfvtHEFf_7Q3"
      },
      "outputs": [],
      "source": [
        "def fm_forward(\n",
        "    unet: TimeConditionalUNet,\n",
        "    x_1: torch.Tensor,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        x_1: (N, C, H, W) input tensor.\n",
        "        num_ts: int, number of timesteps.\n",
        "    Returns:\n",
        "        (,) loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNE8-455IDm3"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def fm__sample(\n",
        "    unet: TimeConditionalUNet,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_hVifFyw20j"
      },
      "outputs": [],
      "source": [
        "class FlowMatching(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: TimeConditionalUNet,\n",
        "        num_ts: int = 50,\n",
        "        img_hw: tuple[int, int] = (28, 28),\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.unet = unet\n",
        "        self.num_ts = num_ts\n",
        "        self.img_hw = img_hw\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return fpm_forward(\n",
        "            self.unet, x, self.num_ts\n",
        "        )\n",
        "\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        img_wh: tuple[int, int],\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, img_wh, self.num_ts, seed\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing class-conditioned UNet"
      ],
      "metadata": {
        "id": "uW2FBjpn8CTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        c: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "        mask: torch.Tensor | None = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "            mask: (N,) mask tensor. If not None, mask out condition when mask == 0.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "vAXZYlOt8Rzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fm_forward(\n",
        "    unet: ClassConditionalUNet,\n",
        "    x_1: torch.Tensor,\n",
        "    c: torch.Tensor,\n",
        "    p_uncond: float,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 3\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        x_1: (N, C, H, W) input tensor.\n",
        "        c: (N,) int64 condition tensor.\n",
        "        p_uncond: float, probability of unconditioning the condition.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        (,) loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "NobmVh4U8BRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def fm_sample(\n",
        "    unet: ClassConditionalUNet,\n",
        "    c: torch.Tensor,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    guidance_scale: float = 5.0,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 4\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        c: (N,) int64 condition tensor. Only for class-conditional\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        guidance_scale: float, CFG scale.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "        (N, T_animation, C, H, W) caches.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "rMW5YeCi8cqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowMatching(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: ClassConditionalUNet,\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "\n",
        "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) loss.\n",
        "        \"\"\"\n",
        "        return fm_forward(\n",
        "            self.unet, x, c, self.p_uncond, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        c: torch.Tensor,\n",
        "        img_wh: tuple[int, int],\n",
        "        guidance_scale: float = 5.0,\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return fm_sample(\n",
        "            self.unet, c, img_wh, self.num_ts, guidance_scale, seed\n",
        "        )"
      ],
      "metadata": {
        "id": "gdQFWwIt8mXh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "cs180-proj5",
      "language": "python",
      "name": "cs180-proj5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}